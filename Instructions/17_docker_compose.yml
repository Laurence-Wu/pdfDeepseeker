# Docker Compose - Complete PDF Translation Pipeline

version: '3.8'

services:
  # API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: pdf-translator-api
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - DB_HOST=postgres
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-google/gemini-pro-1.5}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_WORKERS=${MAX_WORKERS:-10}
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/outputs:/app/outputs
      - ./data/cache:/app/cache
      - ./logs:/app/logs
    depends_on:
      - redis
      - postgres
    networks:
      - pdf-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Worker Service - Extraction
  worker-extraction:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: pdf-worker-extraction
    command: celery -A worker.tasks worker --loglevel=info --concurrency=4 -Q extraction
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - DB_HOST=postgres
      - WORKER_TYPE=extraction
      - USE_GPU=${USE_GPU:-false}
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/cache:/app/cache
      - ./models:/app/models
    depends_on:
      - redis
      - postgres
    networks:
      - pdf-net
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 8G
        reservations:
          cpus: '1'
          memory: 4G

  # Worker Service - Translation
  worker-translation:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: pdf-worker-translation
    command: celery -A worker.tasks worker --loglevel=info --concurrency=2 -Q translation
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - DB_HOST=postgres
      - WORKER_TYPE=translation
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-google/gemini-pro-1.5}
    volumes:
      - ./data/cache:/app/cache
    depends_on:
      - redis
      - postgres
    networks:
      - pdf-net
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 2G

  # Worker Service - VLA Processing
  worker-vla:
    build:
      context: .
      dockerfile: Dockerfile.vla
    container_name: pdf-worker-vla
    command: celery -A worker.tasks worker --loglevel=info --concurrency=1 -Q vla
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - DB_HOST=postgres
      - WORKER_TYPE=vla
      - USE_GPU=${USE_GPU:-true}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/cache:/app/cache
      - ./models:/app/models
    depends_on:
      - redis
      - postgres
    networks:
      - pdf-net
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          cpus: '2'
          memory: 8G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Worker Service - Reconstruction
  worker-reconstruction:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: pdf-worker-reconstruction
    command: celery -A worker.tasks worker --loglevel=info --concurrency=2 -Q reconstruction
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - DB_HOST=postgres
      - WORKER_TYPE=reconstruction
    volumes:
      - ./data/uploads:/app/uploads
      - ./data/outputs:/app/outputs
      - ./data/cache:/app/cache
      - ./fonts:/app/fonts
    depends_on:
      - redis
      - postgres
    networks:
      - pdf-net
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 8G
        reservations:
          cpus: '1'
          memory: 4G

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: pdf-redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy lru
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - pdf-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: pdf-postgres
    environment:
      - POSTGRES_USER=${DB_USER:-translator}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-secure_password}
      - POSTGRES_DB=${DB_NAME:-pdf_translations}
      - POSTGRES_MAX_CONNECTIONS=200
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - pdf-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # Flower - Celery Monitoring
  flower:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: pdf-flower
    command: celery -A worker.tasks flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - pdf-net
    restart: unless-stopped

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: pdf-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - ./data/outputs:/usr/share/nginx/html/outputs
    depends_on:
      - api
    networks:
      - pdf-net
    restart: unless-stopped

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: pdf-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - pdf-net
    restart: unless-stopped

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: pdf-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - pdf-net
    restart: unless-stopped

  # Loki for Log Aggregation
  loki:
    image: grafana/loki:latest
    container_name: pdf-loki
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - pdf-net
    restart: unless-stopped

  # Promtail for Log Shipping
  promtail:
    image: grafana/promtail:latest
    container_name: pdf-promtail
    volumes:
      - ./logs:/var/log
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - pdf-net
    restart: unless-stopped

volumes:
  postgres-data:
  redis-data:
  prometheus-data:
  grafana-data:
  loki-data:

networks:
  pdf-net:
    driver: bridge

# Dockerfile.api
---
# FROM python:3.10-slim
# 
# WORKDIR /app
# 
# # System dependencies
# RUN apt-get update && apt-get install -y \
#     libpoppler-cpp-dev \
#     libmagickwand-dev \
#     && rm -rf /var/lib/apt/lists/*
# 
# COPY requirements.txt .
# RUN pip install --no-cache-dir -r requirements.txt
# 
# COPY . .
# 
# CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Dockerfile.worker
---
# FROM python:3.10-slim
# 
# WORKDIR /app
# 
# # System dependencies
# RUN apt-get update && apt-get install -y \
#     libpoppler-cpp-dev \
#     tesseract-ocr \
#     git \
#     && rm -rf /var/lib/apt/lists/*
# 
# COPY requirements.txt .
# RUN pip install --no-cache-dir -r requirements.txt
# 
# COPY . .
# 
# CMD ["celery", "-A", "worker.tasks", "worker", "--loglevel=info"]

# Dockerfile.vla
---
# FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04
# 
# WORKDIR /app
# 
# # Python and system dependencies
# RUN apt-get update && apt-get install -y \
#     python3.10 python3-pip \
#     libpoppler-cpp-dev \
#     git \
#     && rm -rf /var/lib/apt/lists/*
# 
# COPY requirements.txt .
# RUN pip3 install --no-cache-dir -r requirements.txt
# RUN pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121
# 
# COPY . .
# 
# CMD ["celery", "-A", "worker.tasks", "worker", "--loglevel=info"]